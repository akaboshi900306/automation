{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# upload to GBQ and Remove file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, sys\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas_gbq\n",
    "import datetime\n",
    "from google.cloud import bigquery\n",
    "import win32com.client\n",
    "from win32com.client import Dispatch, constants\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "# Open a file\n",
    "path = r\"\\\\CPNVFS04\\depts\\HD\\IPR\\Parm Sim\"\n",
    "##path = \"C:\\Users\\yxg0rzh\\OneDrive - The Home Depot\\Desktop\\New folder (2)\"\n",
    "dirs = os.listdir(path)\n",
    "##path = r\"C:\\Users\\yxg0rzh\\OneDrive - The Home Depot\\Desktop\\Transfers_tl\\FW 24 Due 5PM 7-13-20\\COMPILED\"\n",
    "\n",
    "##This would print all the files and directories\n",
    "for file in dirs:\n",
    "    URL = os.path.join(path, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\CPNVFS04\\depts\\HD\\IPR\\Parm Sim\\Cabinet Min Test MKT 4.csv\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(path):\n",
    "    URL = os.path.join(path, file)\n",
    "    if os.path.isdir(URL):\n",
    "        # skip directories\n",
    "        continue\n",
    "    print(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours = 4\n",
    "hours_added = datetime.timedelta(hours = hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\CPNVFS04\\depts\\HD\\IPR\\Parm Sim\\Cabinet Min Test MKT 4.csv Trumping_Level                int64\n",
      "Type                          int64\n",
      "Store_Group                 float64\n",
      "Volume_Id                   float64\n",
      "Velocity_Id                  object\n",
      "SKU                         float64\n",
      "SKU_Grp                     float64\n",
      "Store                       float64\n",
      "Parm_code                     int64\n",
      "Parm_Value                  float64\n",
      "Eff_Begin_date               object\n",
      "Eff_End_date                 object\n",
      "Start_Fscl_Wk_nbr           float64\n",
      "End_Fscl_Wk_nbr             float64\n",
      "Param_Desc                   object\n",
      "OOTL_Reason_Code             object\n",
      "time                 datetime64[ns]\n",
      "dtype: object\n",
      "Loaded 6389 rows into analytics-supplychain-thd:akaboshi_test.sam_test2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yxg0rzh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\google\\auth\\_default.py:69: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "1it [00:00,  6.05it/s]\n"
     ]
    }
   ],
   "source": [
    "path1 = r\"\\\\CPNVFS04\\depts\\HD\\IPR\\Parm Sim\\Archive\"\n",
    "combine = pd.DataFrame()\n",
    "for file in dirs:\n",
    "    URL = os.path.join(path, file)\n",
    "    if os.path.isdir(URL):\n",
    "        # skip directories\n",
    "        continue\n",
    "    try:\n",
    "        df = pd.read_csv(URL, header=0)\n",
    "        df.columns = [a.replace(\" \",\"_\") for a in df.columns.values]\n",
    "    except:\n",
    "        df = pd.read_excel(URL, header=0)\n",
    "        df.columns = [a.replace(\" \",\"_\") for a in df.columns.values]\n",
    "    df = df.astype({'Trumping_Level': 'int64', \n",
    "               'Type': 'int64', \n",
    "               'Store_Group':'float64', \n",
    "               'Volume_Id':'float64',\n",
    "               'Velocity_Id':'str',\n",
    "               'SKU':'float64',\n",
    "               'SKU_Grp':'float64',\n",
    "               'Store': 'float64',\n",
    "               'Parm_code':'int64',\n",
    "               'Parm_Value':'float64',\n",
    "               'Eff_Begin_date':'object',\n",
    "               'Eff_End_date':  'object',\n",
    "               'Start_Fscl_Wk_nbr':'float64',\n",
    "               'End_Fscl_Wk_nbr':'float64',\n",
    "               'Param_Desc' : 'object',\n",
    "               'OOTL_Reason_Code' :'object'})\n",
    "    df[\"time\"] = datetime.datetime.now() + hours_added\n",
    "\n",
    "    \n",
    "    \n",
    "    combine = pd.concat([combine, df],ignore_index=True)\n",
    "    combine = combine.dropna(how='all')\n",
    "    shutil.move(URL, os.path.join(path1, file))\n",
    "    \n",
    "print (URL, combine.dtypes)\n",
    "print(\"Loaded {} rows into {}:{}.\".format(len(combine),'analytics-supplychain-thd', \"akaboshi_test.sam_test2\"))\n",
    "#pandas_gbq.to_gbq(combine, \"akaboshi_test.Aug24th\", if_exists = \"replace\" ,project_id='analytics-supplychain-thd')\n",
    "pandas_gbq.to_gbq(combine, \"akaboshi_test.sam_test2\", if_exists = \"replace\" ,project_id='analytics-supplychain-thd')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yxg0rzh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:703: FutureWarning: Converting timezone-aware DatetimeArray to timezone-naive ndarray with 'datetime64[ns]' dtype. In the future, this will return an ndarray with 'object' dtype where each element is a 'pandas.Timestamp' with the correct 'tz'.\n",
      "\tTo accept the future behavior, pass 'dtype=object'.\n",
      "\tTo keep the old behavior, pass 'dtype=\"datetime64[ns]\"'.\n",
      "  subarr = construct_1d_object_array_from_listlike(subarr)\n"
     ]
    }
   ],
   "source": [
    "from oauth2client.client import GoogleCredentials\n",
    "from googleapiclient import discovery\n",
    "\n",
    "## reads BQ tables into Data Frames\n",
    "from pandas_gbq import read_gbq \n",
    "from pandas_gbq import to_gbq\n",
    "from pandas import DataFrame \n",
    "from datetime import date \n",
    "#credentials = GoogleCredentials.get_application_default()\n",
    "#bq = discovery.build('bigquery', 'v2', credentials=credentials)\n",
    "query = \"SELECT  distinct LDAP,EMAIL, CRT_TS from SXR_PARM_SIM.IMPACT_SUMMARY where CRT_TS >= TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL -10 MINUTE)\"\n",
    "#query = \" SELECT  distinct LDAP,EMAIL from AXM3066.parm_sim_summary_test where CRT_TS>= TIMESTAMP_SUB(CURRENT_TIMESTAMP(),INTERVAL 15 MINUTE)\"\n",
    "df = pd.read_gbq(query, 'analytics-supplychain-thd', dialect = 'standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LDAP</th>\n",
       "      <th>EMAIL</th>\n",
       "      <th>CRT_TS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DJA57GH</td>\n",
       "      <td>DAVAN_J_ABNEY@homedepot.com</td>\n",
       "      <td>2021-02-11 15:22:09.259534+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      LDAP                        EMAIL                           CRT_TS\n",
       "0  DJA57GH  DAVAN_J_ABNEY@homedepot.com 2021-02-11 15:22:09.259534+00:00"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    query = \"SELECT * from SXR_PARM_SIM.IMPACT_SUMMARY where LDAP =\" + \"'\"+str(row[\"LDAP\"])+\"'\" + \" and CRT_TS = \" + \"'\"+str(row[\"CRT_TS\"])+\"'\"\n",
    "    query1 = \"SELECT * from SXR_PARM_SIM.STR_SKU_SUMMARY where LDAP =\" + \"'\"+str(row[\"LDAP\"])+\"'\" + \" and CRT_TS = \" + \"'\"+str(row[\"CRT_TS\"])+\"'\"\n",
    "    data = pd.read_gbq(query, 'analytics-supplychain-thd', dialect = 'standard')\n",
    "    path= 'C:/Users/yxg0rzh/OneDrive - The Home Depot/Desktop/New folder (2)/sam_test//'\n",
    "    data.to_csv(os.path.join(path, 'sam_test ' + str(row[\"LDAP\"]) + '.csv'),index=False)    \n",
    "    \n",
    "    const=win32com.client.constants\n",
    "    olMailItem = 0x0\n",
    "    obj = win32com.client.Dispatch(\"Outlook.Application\")\n",
    "    newMail = obj.CreateItem(olMailItem)\n",
    "    newMail.Subject = \"Parm Sim Results\"\n",
    "# newMail.Body = \"I AM\\nTHE BODY MESSAGE!\"\n",
    "    newMail.BodyFormat = 2 # olFormatHTML https://msdn.microsoft.com/en-us/library/office/aa219371(v=office.11).aspx\n",
    "    newMail.HTMLBody = \"<HTML><BODY>Please find results of your parameter simulation attached. Get store-SKU results with BQ query below:</BODY></HTML>\"+ query1\n",
    "#    newMail.To = \"yunzhong_gao@homedepot.com\"\n",
    "    newMail.To = row[\"EMAIL\"]\n",
    "    attachment1 = os.path.join(path, 'sam_test ' + str(row[\"LDAP\"]) + '.csv')\n",
    "    newMail.Attachments.Add(Source=attachment1)\n",
    "    newMail.display()\n",
    "    newMail.Send()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    query = \"SELECT * from SXR_PARM_SIM.IMPACT_SUMMARY where LDAP =\" + \"'\"+str(row[\"LDAP\"])+\"'\" + \" and CRT_TS = \" + \"'\"+str(row[\"CRT_TS\"])+\"'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SELECT * from SXR_PARM_SIM.IMPACT_SUMMARY where LDAP ='AXM3066' and CRT_TS = '2020-08-12 20:24:14.343881+00:00'\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/yxg0rzh/OneDrive - The Home Depot/Desktop/New folder (2)/sam_test//sam_test YXG0RZ.csv'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(path, 'sam_test ' + str(row[\"LDAP\"]) + '.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
